{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preproprocessing for zic2 paper using deep lab but\n",
    "This noteboook contains the step taken to preprocess the data for the experiments \n",
    "using deep lab cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is to create a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.5...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut as dp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\m_801_day_3_trial_3_20230803_154825.avi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join,isdir,abspath\n",
    "videos_for_training = r\"C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\"\n",
    "analysed_path=r'C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\analysed_videos'\n",
    "videos_path = [videos_for_training+f'\\{f}' for f in (listdir(videos_for_training)) if f.split('.')[-1]=='avi' ]\n",
    "videos_path=videos_path[-1]\n",
    "videos_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abspath(videos_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN THIS to create a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\"\n",
      "Created \"C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\labeled-data\"\n",
      "Created \"C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\training-datasets\"\n",
      "Created \"C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\dlc-models\"\n",
      "7  videos from the directory C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\used_for_trainnig were added to the project.\n",
      "Copying the videos\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_140308.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_140726.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_140815.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_142133.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_143348.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_144530.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_145111.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_145624.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_151605 macho trial 1.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_151605_macho_trial_1.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_152231 hembra trial 1.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_152231_hembra_trial_1.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_153031 macho trial 2.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_153656 hembra trial 2.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_154258 macho trial 3.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_155015 hembra trial 3 ipsofacto.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_161848.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_162909.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_164655.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_165447.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_171248.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_172403.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_140308.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_05_20230605_142133.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_151605_macho_trial_1.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_152231_hembra_trial_1.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_160648.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_161848.avi\n",
      "C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\videos\\Exp_2023_06_06_20230606_162909.avi\n",
      "Generated \"C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-30\\config.yaml\"\n",
      "\n",
      "A new project with name zic2-cruz-2023-11-30 is created at C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2 and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "# config_path=dp.create_new_project(project='zic2',\n",
    "#                      experimenter='cruz',\n",
    "#                      videos=videos_path,\n",
    "#                        copy_videos=True,\n",
    "#                        working_directory=Path(r'C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2'),\n",
    "#                         videotype='.avi',\n",
    "#                         multianimal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.add_new_videos(config=config_path,\n",
    "                 videos=videos_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract framnes using a uniform method. There are allso kemans aklgorithms to extract less related frames. And also manuel extraction.\n",
    "userfeedback=True (in case of retraining to extract new unlabelled frames). See that in labeled that i can check myu labelled and unlabelled frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 396.5  seconds.\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 208.38  seconds.\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 48.05  seconds.\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 372.15  seconds.\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 459.77  seconds.\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 600.88  seconds.\n",
      "Frames were successfully extracted, for the videos listed in the config.yaml file.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (Note, you should label frames extracted from diverse videos (and many videos; we do not recommend training on single videos!)).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt \n",
    "#important to crop interactively the image\n",
    "dp.extract_frames(config_path,\n",
    "                  mode='automatic',\n",
    "                  algo='uniform',\n",
    "                  crop='GUI', userfeedback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.label_frames(config_path=config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check annotated frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by cruz.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 49.83it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 43.34it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 41.76it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 45.89it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 45.46it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 45.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dp.check_labels(config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a trainning /test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 63,  81,   2,  87,  21,  66, 119,  39,  99,  13,  84,  43,  29,\n",
       "           76,  53,   3,  83,  14,  30,  98,  19,  22,  17,  31,  46,  27,\n",
       "           68,  64, 103,  41, 115,  37, 111,  49,  70, 112,  38,  69,  50,\n",
       "          107,  57,  94,  26,  96,  79, 113,  55,  73,  56,  65, 108,  78,\n",
       "           51, 114,  89,   1,  90,  35,  77,  62, 117,  67,  93,  60,  61,\n",
       "           88,  58,  10,   4, 110,  45, 118,  23, 106,  32,  52,   6,  40,\n",
       "           80,   0,  34,  97,  28,  92,  11, 105,   7,  71,  15,  44,  16,\n",
       "           18,  75,  47,  86,  36,  59,  54,  48,   5, 109,  95,  24,  85,\n",
       "           42, 101,  33, 102,  25,  72, 100, 116,  91,  82]),\n",
       "   array([  8,  12,  74, 104,   9,  20])))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.create_training_dataset(config=config_path, \n",
    "                           augmenter_type='imgaug')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First chech graphics card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb  6 10:10:58 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.84                 Driver Version: 545.84       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090      WDDM  | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   37C    P8              21W / 450W |    966MiB / 24564MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2764    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      4580    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7096    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10248    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11084    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     11236    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13552    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     13808    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     14920    C+G   ...AppData\\Roaming\\Spotify\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A     15044    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15904    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     17360    C+G   ...pIntegrations\\Grammarly.Desktop.exe    N/A      |\n",
      "|    0   N/A  N/A     17440    C+G   ...al\\Discord\\app-1.0.9032\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     18480    C+G   ...ft Office\\root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A     19412    C+G   ...n\\121.0.2277.106\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     20172    C+G   ...n\\121.0.2277.106\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     20396    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.train_network(config=config_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5]],\n",
      " 'all_joints_names': ['nose', 'LeftEar', 'RightEar', 'Body', 'Tail', 'Cricket'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_zic2Nov29\\\\zic2_cruz95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'c:\\\\Users\\\\arturoV\\\\AppData\\\\Local\\\\miniconda3\\\\envs\\\\tf\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 6,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\dlc-models\\\\iteration-0\\\\zic2Nov29-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "c:\\Users\\arturoV\\AppData\\Local\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_zic2Nov29shuffle1_850000  with # of training iterations: 850000\n",
      "Running evaluation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [00:11, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-850000\n",
      "Results for 850000  training iterations: 95 1 train error: 1.04 pixels. Test error: 7.53  pixels.\n",
      "With pcutoff of 0.6  train error: 1.04 pixels. Test error: 7.53 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:04<00:00, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dp.evaluate_network(config_path,Shuffles=[1], plotting=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check video path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\m_801_day_3_trial_3_20230803_154825.avi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse videos with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-850000 for model C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\dlc-models\\iteration-0\\zic2Nov29-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arturoV\\AppData\\Local\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\m_801_day_3_trial_3_20230803_154825.avi\n",
      "Loading  C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\m_801_day_3_trial_3_20230803_154825.avi\n",
      "Duration of video [s]:  66.7 , recorded with  40.0 fps!\n",
      "Overall # of frames:  2668  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 2632/2668 [00:13<00:00, 308.96it/s]c:\\Users\\arturoV\\AppData\\Local\\miniconda3\\envs\\tf\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py:886: UserWarning: Could not decode frame #2666.\n",
      "  warnings.warn(f\"Could not decode frame #{counter}.\")\n",
      "c:\\Users\\arturoV\\AppData\\Local\\miniconda3\\envs\\tf\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\predict_videos.py:886: UserWarning: Could not decode frame #2667.\n",
      "  warnings.warn(f\"Could not decode frame #{counter}.\")\n",
      "100%|█████████▉| 2666/2668 [00:13<00:00, 201.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_zic2Nov29shuffle1_850000'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dp.analyze_videos(config_path, videos=videos_path, videotype='avi',save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\m_801_day_3_trial_3_20230803_154825.avi\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "dp.filterpredictions(config_path, videos_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\m_801_day_3_trial_3_20230803_154825.avi and data.\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "dp.plot_trajectories(config_path,videos_path,filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\m_801_day_3_trial_3_20230803_154825.avi'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\m_801_day_3_trial_3_20230803_154825.avi\n",
      "Loading C:\\Users\\arturoV\\Desktop\\gesture_models\\zic2\\zic2-cruz-2023-11-29\\videos\\m_801_day_3_trial_3_20230803_154825.avi and data.\n",
      "Duration of video [s]: 66.7, recorded with 40.0 fps!\n",
      "Overall # of frames: 2668 with cropped frame dimensions: 640 360\n",
      "Generating frames and creating video.\n",
      "[WinError 2] El sistema no puede encontrar el archivo especificado\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.create_labeled_video(config_path,videos_path, save_frames = True,videotype='avi',filtered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_140308.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_140726.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_140815.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_142133.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_143348.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_144530.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_145111.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_05_20230605_145624.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_151605 macho trial 1.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_151605_macho_trial_1.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_152231 hembra trial 1.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_152231_hembra_trial_1.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_153031 macho trial 2.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_153656 hembra trial 2.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_154258 macho trial 3.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_155015 hembra trial 3 ipsofacto.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_161848.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_162909.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_164655.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_165447.avi',\n",
       " 'C:\\\\Users\\\\arturoV\\\\Desktop\\\\gesture_models\\\\zic2\\\\zic2-cruz-2023-11-29\\\\videos\\\\Exp_2023_06_06_20230606_171248.avi']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
